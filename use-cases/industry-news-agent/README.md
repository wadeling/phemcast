# Industry News Aggregation Agent

A comprehensive AI-powered system that automatically crawls company blogs, analyzes content, and generates weekly industry reports using LangGraph for workflow orchestration.

## ğŸš€ Features

- **Intelligent Web Scraping**: Crawls multiple company blog URLs with rate limiting and error handling
- **AI-Powered Content Analysis**: Uses OpenAI to summarize and analyze article content
- **Multi-Format Report Generation**: Creates reports in both Markdown and PDF formats
- **Web Interface**: User-friendly web application for inputting blog URLs and email addresses
- **Email Delivery**: Automatically sends generated reports to specified email addresses
- **LangGraph Workflow**: Robust state management and workflow orchestration

## ğŸ“‹ Requirements

- Python 3.8+
- OpenAI API key
- SMTP email credentials
- Virtual environment (recommended)

## ğŸ› ï¸ Installation

1. **Clone the repository and navigate to the project:**
   ```bash
   cd use-cases/industry-news-agent
   ```

2. **Create and activate a virtual environment:**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables:**
   ```bash
   cp .env.example .env
   # Edit .env with your API keys and email settings
   ```

## ğŸ”§ Configuration

Create a `.env` file with the following variables:

```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
OPENAI_BASE_URL=https://api.openai.com/v1  # Optional: for OpenAI-compatible endpoints

# Email Configuration
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
EMAIL_USERNAME=your_email@gmail.com
EMAIL_PASSWORD=your_app_password

# Web Scraping Configuration
REQUEST_DELAY=1.0
MAX_RETRIES=3
TIMEOUT=30

# Application Configuration
DEBUG=True
HOST=0.0.0.0
PORT=8000
```

## ğŸ—ï¸ Project Structure

```
industry-news-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agent.py              # Main LangGraph agent definition
â”‚   â”œâ”€â”€ tools.py              # Web scraping and analysis tools
â”‚   â”œâ”€â”€ models.py             # Pydantic models and state management
â”‚   â”œâ”€â”€ web_interface.py      # FastAPI web application
â”‚   â”œâ”€â”€ email_service.py      # Email sending functionality
â”‚   â””â”€â”€ report_generator.py   # Report generation (Markdown/PDF)
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ basic_agent/          # Simple LangGraph agent example
â”‚   â”œâ”€â”€ web_interface/        # FastAPI web app example
â”‚   â”œâ”€â”€ email_service/        # Email service example
â”‚   â””â”€â”€ report_generator/     # Report generation example
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                 # Unit tests for each component
â”‚   â””â”€â”€ integration/          # Integration tests
â”œâ”€â”€ PRPs/                     # Product Requirements Prompts
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env.example              # Environment variables template
â””â”€â”€ README.md                 # This file
```

## ğŸš€ Usage

### Web Interface

1. **Start the web server:**
   ```bash
   python -m src.web_interface
   ```

2. **Open your browser** and navigate to `http://localhost:8000`

3. **Enter company blog URLs** (one per line) and your email address

4. **Submit the form** to start the report generation process

### Command Line Interface

```bash
# Generate a report for specific URLs
python -m src.cli --urls "https://blog.company1.com,https://blog.company2.com" --email user@example.com

# Generate a report from a file containing URLs
python -m src.cli --url-file urls.txt --email user@example.com
```

## ğŸ”„ LangGraph Workflow

The agent uses LangGraph for workflow orchestration with the following nodes:

1. **URL Validation**: Validates and normalizes blog URLs
2. **Content Scraping**: Crawls articles from each blog with rate limiting
3. **Content Analysis**: Uses AI to summarize and analyze articles
4. **Report Generation**: Creates Markdown and PDF reports
5. **Email Delivery**: Sends reports to specified email addresses

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest

# Run specific test categories
pytest tests/unit/
pytest tests/integration/

# Run with coverage
pytest --cov=src
```

## ğŸ“Š Supported Blog Platforms

- **WordPress**: Standard WordPress blogs with RSS feeds
- **Medium**: Medium publications and personal blogs
- **Custom CMS**: Generic HTML parsing for custom platforms
- **RSS Feeds**: Direct RSS feed processing

## ğŸ”’ Security & Best Practices

- **Rate Limiting**: Configurable delays between requests to avoid being blocked
- **User Agent Rotation**: Rotates user agents to avoid detection
- **Error Handling**: Robust error handling for network failures and parsing errors
- **Content Deduplication**: Avoids processing the same articles multiple times
- **Environment Variables**: Secure configuration management

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Troubleshooting

### Common Issues

1. **Rate Limiting**: If you're getting blocked, increase the `REQUEST_DELAY` in your `.env` file
2. **Email Issues**: Make sure to use an app password for Gmail, not your regular password
3. **API Limits**: Monitor your OpenAI API usage to avoid hitting rate limits
4. **Memory Issues**: For large reports, consider processing URLs in batches

### Getting Help

- Check the logs for detailed error messages
- Verify your environment variables are set correctly
- Test individual components using the examples in the `examples/` directory 